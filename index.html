<!DOCTYPE html>
<html lang="pt-br">
  <head>
    <meta charset="UTF-8" />
    <title>AR com Vídeo e WebXR</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
      body { margin: 0; overflow: hidden; }
      button {
        position: absolute;
        z-index: 10;
        top: 10px;
        left: 10px;
        padding: 10px;
      }
    </style>
  </head>
  <body>
    <button id="start-ar">Iniciar AR</button>

    <script type="module">
      import * as THREE from 'https://unpkg.com/three@0.158.0/build/three.module.js';

      let scene, camera, renderer, videoMesh, xrRefSpace;
      const video = document.createElement('video');
      video.src = './assets/ayo_teste.mp4';
      video.crossOrigin = 'anonymous';
      video.setAttribute('playsinline', 'true');
      video.muted = true;
      video.loop = true;

      init();

      document.getElementById('start-ar').addEventListener('click', () => startAR(video));

      function init() {
        scene = new THREE.Scene();
        camera = new THREE.PerspectiveCamera();

        renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.xr.enabled = true;
        renderer.xr.setReferenceSpaceType('local');
        document.body.appendChild(renderer.domElement);
      }

      async function startAR(video) {
        const session = await navigator.xr.requestSession('immersive-ar', {
          requiredFeatures: ['image-tracking']
        });

        renderer.xr.setSession(session);
        xrRefSpace = await session.requestReferenceSpace('local');

        const imageBitmap = await fetch('./targets/target_1.png')
          .then(res => res.blob())
          .then(createImageBitmap);

        session.updateTargetImages([{ image: imageBitmap, widthInMeters: 0.15 }]);

        const texture = new THREE.VideoTexture(video);
        const material = new THREE.MeshBasicMaterial({ map: texture });
        const geometry = new THREE.PlaneGeometry(0.15, 0.085); // proporção 16:9

        videoMesh = new THREE.Mesh(geometry, material);
        videoMesh.visible = false;
        scene.add(videoMesh);

        renderer.setAnimationLoop((time, frame) => {
          const results = frame.getImageTrackingResults();

          for (const result of results) {
            const state = result.trackingState;
            if (state === "tracked") {
              const pose = frame.getPose(result.imageSpace, xrRefSpace);
              if (pose) {
                videoMesh.visible = true;
                videoMesh.matrix.fromArray(pose.transform.matrix);
                videoMesh.matrix.decompose(videoMesh.position, videoMesh.quaternion, videoMesh.scale);
                if (video.paused) video.play();
              }
            } else {
              videoMesh.visible = false;
              if (!video.paused) video.pause();
            }
          }

          renderer.render(scene, camera);
        });
      }
    </script>
  </body>
</html>
